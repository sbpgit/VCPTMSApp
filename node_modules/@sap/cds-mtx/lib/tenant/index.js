const path = require('path');
const cds = require('@sap/cds');

const Logger = require('../helper/logger');
const FileSystemHelper = require('../helper/file_system_helper');
const HdiBuilder = require('../build/hdi_builder');
const SecurityHelper = require('../helper/security_helper');
const TenantRequestHelper = require('../helper/tenant_request_helper');
const SaasRegistryHelper = require('../helper/cf/saas_registry_helper');
const HttpHelper = require('../helper/http_helper');
const CfUrlHelper = require('../helper/cf/url_helper');
const GlobalConnections = require('../helper/global_connections');
const getDomain = GlobalConnections.getDomain;
const TenantMissingError = require('../errors/tenant_missing_error');
const NativeExtensionProvidedError = require('../errors/native_extension_provided_error');
const LinterError = require('../errors/linter_error');
const TenantRunner = require('../runner/tenant_runner');
const Linter = require('../linter/linter_runner');
const Job = require('../jobs/job');

const DEFAULT_SUBSCRIPTION_URL = 'not_provided';
const DEFAULT_PARALLEL_UPGRADE_LIMIT = 4;

const { UPDATE_TYPE, COMPILED_FILES, METADATA_SERVICE_TYPE  } = require('../../config/constants');
const JobExecutor = require('../jobs/job_executor');
const LogCollector = require('../helper/log_collector');

const { EDMX, CSN } = METADATA_SERVICE_TYPE;

class Tenant {

    static get logger() {
        return this._logger = this._logger || Logger('TENANT');
    }

    static async create(tenantId, context, asyncSettings, authHeader) {
        if (asyncSettings) {
            Tenant.logger.debug('Starting asynchronous tenant creation. Callback URLs:', asyncSettings);
            return await this.createAsync(tenantId, context, asyncSettings, authHeader);
        } else {
            Tenant.logger.debug('Starting synchronous tenant creation');
            return (await this.createSync({}, tenantId, context)) || DEFAULT_SUBSCRIPTION_URL;
        }
    }

    static async createAsync(tenantId, context, asyncSettings, authHeader) {
        const tenantMetadata = context.data;

        async function sendResult(job) {
            if (asyncSettings.noCallback) {
                return;
            }

            if (job.jobStatus === Job.EXECUTION_STATUS.FINISHED) {
                // TODO get subscription url from job result
                const subscriptionUrl = job.result || TenantRequestHelper.getSubscriptionUrl(tenantMetadata) || DEFAULT_SUBSCRIPTION_URL;
                if (!asyncSettings.mtxCallbackUrl && !subscriptionUrl) { // only log if mandatory
                    Tenant.logger.error('No subscription url for saas registry provided by application');
                }

                await Tenant._sendResult(asyncSettings, tenantId, {
                    status: SaasRegistryHelper.SUCCEEDED,
                    message: `Tenant ${tenantId} successfully created`,
                    subscriptionUrl: subscriptionUrl || '',
                    saasRequestPayload: tenantMetadata
                }, authHeader);
            } else if (job.jobStatus === Job.EXECUTION_STATUS.FAILED) {
                const subscriptionUrl = TenantRequestHelper.getSubscriptionUrl(tenantMetadata);
                if (!asyncSettings.mtxCallbackUrl && !subscriptionUrl) { // only log if mandatory
                    Tenant.logger.error('No subscription url for saas registry provided by application');
                }

                await Tenant._sendResult(asyncSettings, tenantId, {
                    status: SaasRegistryHelper.FAILED,
                    message: job.error.message,
                    subscriptionUrl: subscriptionUrl || '',
                    saasRequestPayload: tenantMetadata
                }, authHeader);
                Tenant.logger.error(job.error);
            }
        }

        return GlobalConnections.jobExecutor.submit(tenantId, context, this.createSync, [tenantId, context], { callback: sendResult });
    }

    static async createSync(status, tenantId, context) {
        const tenantPersistenceService = await cds.connect.to('TenantPersistenceService');
        // it is important to open a new transaction here with the given context as this can also be called
        // by a job that is no longer running in the right request context
        const tx = tenantPersistenceService.tx(context);
        return (await tx.createTenant(tenantId, context.data)) || CfUrlHelper.createDefaultAppUrl(context.data.subscribedSubdomain);
    }

    static async _sendResult(callbackUrls, tenantId, { status, message, subscriptionUrl, saasRequestPayload }, authHeader) {

        const usedCallbackUrl = callbackUrls.mtxCallbackUrl ? callbackUrls.mtxCallbackUrl : callbackUrls.callbackUrl;
        const saasCallbackUrl = callbackUrls.mtxCallbackUrl ? callbackUrls.callbackUrl : undefined;

        try {
            return await SaasRegistryHelper.sendResult(usedCallbackUrl, tenantId, { status, message, subscriptionUrl, saasCallbackUrl, saasRequestPayload }, authHeader);
        } catch (error) {
            Tenant.logger.warn(`Could not send onboarding result ${status} to saas-registry: ${error}`);
        }
    }

    static async delete(tenantId, requestId, context, asyncSettings, authHeader) {
        if (asyncSettings) {
            Tenant.logger.debug('Starting asynchronous tenant deletion. Callback URL: %s', JSON.stringify(asyncSettings));
            return this.deleteAsync(tenantId, requestId, context, asyncSettings, authHeader);
        } else {
            Tenant.logger.debug('Starting synchronous tenant deletion');
            return await this.deleteSync(null, tenantId, context);
        }
    }

    static async deleteAsync(tenantId, requestId, context, asyncSettings, authHeader) {

        const tenantMetadata = context.data;

        async function sendResult(job) {
            if (asyncSettings.noCallback) {
                return;
            }

            if (job.jobStatus === Job.EXECUTION_STATUS.FINISHED) {
                await Tenant._sendResult(asyncSettings, tenantId, {
                    status: SaasRegistryHelper.SUCCEEDED,
                    message: `Tenant ${tenantId} successfully deleted`,
                    tenantId: tenantId,
                    saasRequestPayload: tenantMetadata
                }, authHeader);
            } else if (job.jobStatus === Job.EXECUTION_STATUS.FAILED) {
                await Tenant._sendResult(asyncSettings, tenantId, {
                    status: SaasRegistryHelper.FAILED,
                    message: job.error.message,
                    tenantId: tenantId,
                    saasRequestPayload: tenantMetadata
                }, authHeader);
            }
        }

        return GlobalConnections.jobExecutor.submit(tenantId, context, this.deleteSync, [tenantId, context], { callback: sendResult });
    }

    static async deleteSync(status, tenantId, context) {
        const tenantPersistenceService = await cds.connect.to('TenantPersistenceService');

        const subscriptionData = await (async () => {
            try {
                return await tenantPersistenceService.getTenantMetadata(tenantId);
            } catch (error) {
                // be robust here to allow a repeated delete call even if the meta tenant has already been deleted
                return {};
            }
        })();

        // it is important to open a new transaction here with the given context as this can also be called
        // by a job that is no longer running in the right request context
        const tx = tenantPersistenceService.tx(context);
        return tx.deleteTenant(tenantId, subscriptionData);
    }

    static async extend(status, tenantId, context, extensionFiles, undeployExtension = false, extensionsToRemove = null) {
        return TenantRunner.runSynchronized(tenantId, async() => {
            return Tenant._extendInternal(status, tenantId, context, extensionFiles, undeployExtension, extensionsToRemove);
        });
    }

    static async _extendInternal(status, tenantId, context, newExtensionFiles, undeployExtension = false, extensionsToRemove = null) {

        // existing extensions have to be included to avoid accidental undeployments
        const _includeExtension = !undeployExtension || extensionsToRemove;
        Tenant.logger.debug(`Extend - undeploy extension: ${undeployExtension}, includeExtension: ${_includeExtension}`);

        const instanceData = await GlobalConnections.applicationDataPersistence.getInstanceData(tenantId);
        if (!instanceData) {
            Tenant.logger.debug(`Tenant does not exist: ${tenantId}`);
            throw new TenantMissingError(tenantId);
        }

        const builder = new HdiBuilder(tenantId);

        const metadataPersistence = await GlobalConnections.createMetadataPersistenceAndConnect(tenantId, true);

        try {

            const { basemodelFiles, migrationFiles, extensionFiles } = await metadataPersistence.getModelFilesRaw(_includeExtension);

            // add new extensions - make sure filenames are unix compliant
            const extension = new Map(newExtensionFiles);
            const extensionUnix = new Map();
            extension.forEach((content, filename) => {
                const unixFilename = FileSystemHelper.unixPath(filename);
                extensionUnix.set(unixFilename, content);
            });

            // merge new extensions with existing extensions
            const extensionFiltered = Tenant._filterExtension(extensionUnix);
            const allExtensionFiles = new Map([...extensionFiles, ...extensionFiltered]);

            // remove extensions marked for deletion
            if (extensionsToRemove) {
                Tenant.logger.debug(`Extension files are removed: ${extensionsToRemove}`);
                for (const extensionToRemove of extensionsToRemove) {
                    allExtensionFiles.delete(extensionToRemove);
                }
            }

            const { basemodelFolders } = await builder.setupProject(basemodelFiles, migrationFiles, allExtensionFiles);

            const { compiledFiles, csnObject, dbDir, languages, services, hana: hanaFiles} = await builder.build(basemodelFolders);

            if (extensionFiltered) {
                const linterWarnings = await Linter.runLinters(builder.projectPath, extensionFiltered, csnObject);
                if (linterWarnings.length > 0) {
                    throw new LinterError(linterWarnings);
                }
            }

            const undeployWhitelist = await metadataPersistence.getUndeployWhitelist();
            const options = { undeployExtension, undeployWhitelist };
            await this._deployToDb(context, dbDir, instanceData, options);

            // retrieve all migration file from build directory
            const allMigrationFiles = await builder.getMigrationFiles();

            await metadataPersistence.saveBuildResults(compiledFiles, hanaFiles, services, languages, allMigrationFiles, undeployExtension);

            // no undeploy, new extensions -> save only new extensions
            // undeploy, new extensions -> save only new extensions
            // undeploy, deleted extensions -> whole set of extensions
            const extensionsToSave = extensionsToRemove ? allExtensionFiles : extensionFiltered;

            if (extensionsToSave) {
                await metadataPersistence.saveExtension(extensionsToSave, undeployExtension);
            }

            await GlobalConnections.applicationDataPersistence.logUpdate(tenantId, getDomain(), UPDATE_TYPE.EXTENSION);

        } finally {
            if (metadataPersistence) {
                await metadataPersistence.destroy();
            }
            await builder.destroy();
        }
    }

    // TODO remove this copy, implement extend also as service
    static async _deployToDb(context, dbDir, instanceData, deployOptions) {

        const tenantPersistenceService = await cds.connect.to('TenantPersistenceService');
        // it is important to open a new transaction here with the given context as this can also be called
        // by a job that is no longer running in the right request context
        const tx = tenantPersistenceService.tx(context);
        return await tx.deployToDb(dbDir, instanceData, deployOptions);
    }

    static async activate(tenantId, content, options) {
        Tenant.logger.debug(`Activate tenant ${tenantId} with options ${options}`);

        return TenantRunner.runSynchronized(tenantId, async () => {
            const metadataPersistence = await GlobalConnections.createMetadataPersistenceAndConnect(tenantId);

            let existingExtensionFiles;
            try {
                existingExtensionFiles = await metadataPersistence.getExtensionFiles();
            } finally {
                if (metadataPersistence) {
                    await metadataPersistence.destroy();
                }
            }

            const extensionFileList = [...existingExtensionFiles.keys()];
            const seqNos = this._getSeqNos(extensionFileList);

            // Get max sequence number to determine the current
            const seqNoMax = Math.max(0, ...seqNos);
            const seqNo = seqNoMax + 1;

            // Patch parsedContent with requires of previous file
            let parsedContent = content;
            if (typeof (content) === 'string') {
                parsedContent = JSON.parse(content);
            }
            const patchedContent = this._patchCsnContent(extensionFileList, seqNoMax, parsedContent);
            const contentString = JSON.stringify(patchedContent);
            const filename = this._generateExtFilename(patchedContent, seqNo);

            const files = [
                [
                    filename,
                    contentString
                ]
            ];

            const status = {};
            const context = cds.context;

            // call non-synchronized extend
            return Tenant._extendInternal(status, tenantId, context, files, false);
        });
    }

    static _getSeqNos(extensionFileList) {
        // const invalidFileList = []; // TODO: What to do with this list?
        return extensionFileList.map((xtnFile) => {
            const match = xtnFile.match(/\.\d+\./g);
            if ( match !== null) {
                return parseInt(match[0].replace(/^\.|\.$/g, ''));
            } else {
                // invalidFileList.push(xtnFile);
                return;
            }
        }).filter(n => n).sort((a, b) => a - b);
    }

    static _patchCsnContent(extensionFileList, seqNoMax, parsedContent) {
        let fileRequired = null;
        if (extensionFileList.length !== 0) {
            const regex = new RegExp(`db/ext.${seqNoMax}.*.csn$`);
            for (let i = 0; i < extensionFileList.length; i++) {
                const match = extensionFileList[i].match(regex, "g");
                if (match !== null) {
                    fileRequired = `./${match[0].replace('db/', '')}`;
                }
            }
            if (fileRequired !== null) {
                if (!parsedContent.requires) {
                    parsedContent["requires"] = [fileRequired];
                } else {
                    const allContent = [parsedContent["requires"], [fileRequired]];
                    let mergedContent = [];
                    allContent.forEach(content => {
                        mergedContent = [...mergedContent, ...content]
                    })
                    parsedContent["requires"] = mergedContent.filter((item,index) =>
                        mergedContent.indexOf(item) === index
                    );
                }
            }
        }
        return parsedContent;
    }

    static _generateExtFilename(content, seqNo) {
        const serialized = [];

        // creates simple unique content string for hash generation - no serialized JSON!
        function serialize(content, serialized) {
            const entries = Object.entries(content);
            entries.sort();
            for (const entry of entries) {
                serialized.push(entry[0]);
                if (typeof(entry[1]) === "object") {
                    serialize(entry[1], serialized);
                } else {
                    serialized.push(entry[1]);
                }
            }
        }

        serialize(content, serialized);
        const hash = SecurityHelper.hash(JSON.stringify(serialized));

        return `db/ext.${seqNo}.${hash}.csn`;
    }

    static _filterExtension(extensionFiles) {
        extensionFiles.forEach((content, filename) => {
            const unixFilename = FileSystemHelper.unixPath(filename);

            if (/.*node_modules\/_base\/.*/.test(unixFilename)) {
                extensionFiles.delete(filename);
            }

            if (/db\/src.*/.test(unixFilename)) {
                throw new NativeExtensionProvidedError();
            }
        });

        return extensionFiles;
    }

    static async getMetadata(tenantId) {
        const tenantPersistenceService = await cds.connect.to('TenantPersistenceService');
        return tenantPersistenceService.getTenantMetadata(tenantId);
    }

    static async getAllWithMetadata() {
        const tenantPersistenceService = await cds.connect.to('TenantPersistenceService');
        return tenantPersistenceService.getAllTenants();
    }

    static async getAllTenantIds() {
        const tenantPersistenceService = await cds.connect.to('TenantPersistenceService');
        return tenantPersistenceService.getAllTenantIds();
    }

    static async upgradeTenant(tenantId, instanceData, deploymentOptions, basemodelBuild, basemodelBuildLogs, isExtended, context) {
        const tenantPersistenceService = await cds.connect.to('TenantPersistenceService');
        // it is important to open a new transaction here with the given context as this can also be called
        // by a job that is no longer running in the right request context
        const tx = tenantPersistenceService.tx(context);
        return tx.upgradeTenant(tenantId, instanceData, deploymentOptions, basemodelBuild, basemodelBuildLogs, isExtended);
    }

    static async updateBaseModelAsync(tenantId, context, tenantIdsToUpdate, autoUndeploy, advancedOptions, authHeader, mtxCallbackurl) {

        async function sendJobResult(job, result) {

            const headers = {'Authorization': authHeader};

            if (job.jobStatus === Job.EXECUTION_STATUS.FINISHED) {

                try {
                    return await HttpHelper.sendJsonRequest('POST', mtxCallbackurl, null, headers, JSON.stringify(result));
                } catch (error) {
                    Tenant.logger.error(error);
                }

            } else if (job.jobStatus === Job.EXECUTION_STATUS.FAILED) {

                try {
                    return await HttpHelper.sendJsonRequest('POST', mtxCallbackurl, null, headers, JSON.stringify(job.error));
                } catch (error) {
                    Tenant.logger.error(error);
                }
            }
        }

        const args = [tenantIdsToUpdate, autoUndeploy, advancedOptions, context];
        const callbackUrl = mtxCallbackurl ? sendJobResult : null;
        return GlobalConnections.jobExecutor.submit(tenantId, context, Tenant.updateBaseModelSync, args, { callback: callbackUrl });
    }

    static async updateBaseModelSync(status, tenantIdsToUpdate, autoUndeploy = false, advancedOptions = null, context = {}) {

        if (!tenantIdsToUpdate || !Array.isArray(tenantIdsToUpdate)) {
            throw new Error(`Cannot update base model with invalid list of tenantIds: ${JSON.stringify(tenantIdsToUpdate)}`);
        }
        if (tenantIdsToUpdate.includes("all")) {
            tenantIdsToUpdate = await Tenant.getAllTenantIds();
        }

        Tenant.logger.debug(`Upgrading tenants: ${tenantIdsToUpdate} with auto-undeploy=${autoUndeploy}`);
        status.tenants = {};

        await (await GlobalConnections.getTenantMetadataPersistenceFactory()).updateBaseModel(context);

        const poolSize = cds.env.get('mtx.jobs.parallelUpgradeLimit') || DEFAULT_PARALLEL_UPGRADE_LIMIT;


        const domain = GlobalConnections.getDomain();
        const extendedTenantIds  = await GlobalConnections.applicationDataPersistence.getExtendedTenantIdsFrom(tenantIdsToUpdate, domain);
        const basemodelTenantIds = tenantIdsToUpdate.filter(tenantId => !extendedTenantIds.includes(tenantId));

        const [firstBasemodelTenantId] = basemodelTenantIds;
        Tenant.logger.debug('Basemodel tenantIds', basemodelTenantIds);
        Tenant.logger.debug('Extended tenantIds', extendedTenantIds);

        let dbDir, compiledFiles, hanaFiles, services, languages, firstMetadataPersistence;
        let basemodelLogCollector;
        let basemodelMigrationFiles;
        const basemodelBuilder = new HdiBuilder();

        try {
            if (firstBasemodelTenantId) {

                let basemodelMetadataPersistence;
                try {
                    if (LogCollector.isEnabled()) {
                        basemodelLogCollector = new LogCollector();
                    }
                    basemodelMetadataPersistence = await GlobalConnections.createMetadataPersistenceAndConnect(firstBasemodelTenantId, true);
                    const newBasemodelMigrationFiles = await basemodelMetadataPersistence.saveBaseModel();
                    const {basemodelFiles, migrationFiles, extensionFiles} = await basemodelMetadataPersistence.getModelFilesRaw(true);
                    const {basemodelFolders} = await basemodelBuilder.setupProject(basemodelFiles, migrationFiles, extensionFiles);
                    const tenantMigrationFiles = await basemodelBuilder.getMigrationFiles();
                    ({
                        compiledFiles,
                        dbDir,
                        languages,
                        services,
                        hana: hanaFiles
                    } = await basemodelBuilder.build(basemodelFolders, basemodelLogCollector));
                    const mergedMigrationFiles = await basemodelBuilder.mergeMigrationFiles(tenantMigrationFiles, newBasemodelMigrationFiles);
                    await FileSystemHelper.writeFilesFromMap(mergedMigrationFiles, path.dirname(dbDir));
                    basemodelMigrationFiles = await basemodelBuilder.getMigrationFiles();
                } finally {
                    if (basemodelMetadataPersistence) await basemodelMetadataPersistence.destroy();
                }
            }

            await JobExecutor.asyncPool(poolSize, tenantIdsToUpdate, async tenantId => {
                const instanceData = await GlobalConnections.applicationDataPersistence.getInstanceData(tenantId);
                const isExtended = extendedTenantIds.includes(tenantId);
                if (!instanceData) {
                    status.tenants[tenantId] = {status: 'NON-EXISTENT', message: ''};
                    Tenant.logger.debug(`Tenant ${tenantId} does not exist`);
                    return;
                }
                status.tenants[tenantId] = {status: 'RUNNING', message: ''};
                status.tenants[tenantId] = await Tenant.upgradeTenant(
                    tenantId,
                    instanceData,
                    {autoUndeploy, advancedOptions},
                    {dbDir, compiledFiles, hanaFiles, services, languages, basemodelMigrationFiles},
                    basemodelLogCollector ? basemodelLogCollector.logs : undefined,
                    isExtended,
                    context
                );
            })
        } finally {
            await basemodelBuilder.destroy();
        }
        return status;
    }

    static async getLanguages(tenantId) {
        const metadataPersistence = await GlobalConnections.createMetadataPersistenceAndConnect(tenantId);

        try {
            const languages = await metadataPersistence.getLanguages();
            Tenant.logger.debug(`Languages: ${languages}`);
            return languages;
        } finally {
            if (metadataPersistence) {
                await metadataPersistence.destroy();
            }
        }
    }

    static async getServices(tenantId) {
        const metadataPersistence = await GlobalConnections.createMetadataPersistenceAndConnect(tenantId);
        try {
            return await metadataPersistence.getServices();
        } finally {
            if (metadataPersistence) {
                await metadataPersistence.destroy();
            }
        }
    }

    static async getModel(tenantId, type, attributes) {
        Tenant.logger.info(`Get model of type '${type}' for tenant ${tenantId} with attributes`, attributes);
        const metadataPersistence = await GlobalConnections.createMetadataPersistenceAndConnect(tenantId);
        try {
            return await metadataPersistence.getModel(tenantId, type, attributes);
        } finally {
            if (metadataPersistence) {
                await metadataPersistence.destroy();
            }
        }
    }

    static _doRecompile(odataVersion) {
        return (odataVersion && odataVersion != cds.env.get('odata.version')) || cds.env.get('mtx.edmx.compile');
    }

    static async getEdmx(tenantId, attributes) {
        if (!this._doRecompile(attributes.odataVersion)) {
            return Tenant.getModel(tenantId, EDMX, attributes)
        } else {
            return Tenant.compileToEdmx(tenantId, attributes);
        }
    }

    static async compileToEdmx(tenantId, { service, language, odataVersion }) {

        Tenant.logger.debug(`Compiling model edmx for tenant: ${tenantId}`);
        Tenant.logger.debug(`Compiling edmx for service ${service}, language ${language}, odata version ${odataVersion}`);
        const metadataPersistence = await GlobalConnections.createMetadataPersistenceAndConnect(tenantId);
        const builder = new HdiBuilder(tenantId);
        try {
            // creates a temporary project and builds the edmx
            // csn.json or odata_csn.json for fallback
            // _i18n/i18n.json

            const files = new Map();

            const csn = await metadataPersistence.getModelContent(COMPILED_FILES.CSN);
            const extendedI18n = await metadataPersistence.getModelContent(COMPILED_FILES.I18N);

            if (extendedI18n) {
                // structured csn + i18n is available
                files.set('csn.json', csn);
                files.set('_i18n/i18n.json', extendedI18n);
                await builder.writeModelFiles(files);
                return await builder.toEdmx(service, odataVersion, language);
            } else {
                // fallback
                files.set('odata_csn.json', csn); // csn is an odata csn

                const baseModelFiles = await metadataPersistence.getBaseModelFilesRaw(); //
                const i18n = baseModelFiles.get('_i18n/i18n.json');
                files.set('_i18n/i18n.json', i18n);

                await builder.writeModelFiles(files);
                return await builder.toEdmxFromOdataCsn(service, odataVersion, language);
            }

        } catch (e) {
            Tenant.logger.error(e);
            throw new Error(`Could not get model for tenant ${tenantId}. Tenant might not be onboarded yet.`);
        } finally {
            await builder.destroy();
            if (metadataPersistence) {
                await metadataPersistence.destroy();
            }
        }
    }

    static async isExtended(tenantId) {
        const domain = GlobalConnections.getDomain();
        return GlobalConnections.applicationDataPersistence.isExtended(tenantId, domain);
    }

    static async getTimestamps(tenantId) {
        try {
            const domain = GlobalConnections.getDomain();
            return await GlobalConnections.applicationDataPersistence.getTimestamps(tenantId, domain);
        } catch (e) {
            return false;
        }
    }
}

module.exports = Tenant;
